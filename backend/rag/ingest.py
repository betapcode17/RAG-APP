import os
from utils.chunk import chunk_text
from llm.embedding import embed  
from vector.chroma import get_collection

async def ingest():
    try:
        docs_path = "data/docs.txt"
        if not os.path.exists(docs_path):
            raise FileNotFoundError("File data/docs.txt kh√¥ng t·ªìn t·∫°i!")
        
        with open(docs_path, "r", encoding="utf-8") as f:
            text = f.read()
        
        chunks = chunk_text(text)

        if not chunks:
            raise ValueError("Kh√¥ng t·∫°o ƒë∆∞·ª£c chunks t·ª´ docs.txt!")

        collection = await get_collection()

        ids = [f"chunk_{i}" for i in range(len(chunks))]
        documents = chunks
        embeddings = []
        metadatas = [{"source": "docs.txt", "chunk_id": i} for i in range(len(chunks))]

        print(f"üîÑ ƒêang embed {len(chunks)} chunks...") 

       
        for i, chunk in enumerate(chunks):
            try:
                embedding = await embed(chunk)
                embeddings.append(embedding)
                print(f"‚úÖ Embed chunk {i+1}/{len(chunks)}")
            except Exception as e:
                print(f"‚ùå L·ªói embed chunk {i+1}: {e}")
                raise  #

       
        collection.add(
            embeddings=embeddings,
            documents=documents,
            metadatas=metadatas,
            ids=ids
        )

        count = collection.count()
        print(f"‚úÖ Ingest ho√†n t·∫•t: {count} chunks v√†o ChromaDB")
    except Exception as error:
        print(f"‚ùå L·ªói ingest: {error}")
        raise 